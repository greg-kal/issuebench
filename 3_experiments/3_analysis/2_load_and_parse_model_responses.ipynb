{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paul/Documents/Repos/partial-writing-aid/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading rpp_step3_qwen25-14b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 23/23 [02:59<00:00,  7.81s/files]\n",
      "Generating train split: 100%|██████████| 3180000/3180000 [00:15<00:00, 202345.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "\n",
    "COLUMNS = ['common_id', 'template_id', 'topic_id', 'topic_polarity', 'call_idx', 'prompt_text', 'response_text', 'eval_text']\n",
    "MODELS = [\"rpp_step3_qwen25-14b\"] #[\"rpp_step3_llama-31-70b\", \"rpp_step3_llama-31-8b\", \"rpp_step3_qwen25-72b\", \"rpp_step3_qwen25-14b\", \"rpp_step3_qwen25-7b\", \"rpp_step3_gpt4o\", \"rpp_step3_olmo2-7b\", \"rpp_step3_olmo2-13b\"]\n",
    "\n",
    "df_dict = {}\n",
    "\n",
    "for model in MODELS:\n",
    "\n",
    "    print('Loading', model)\n",
    "    \n",
    "    ds = load_dataset(f\"musashihinck/{model}\")[\"train\"]\n",
    "    \n",
    "    # sample 100 from ds for debugging\n",
    "    #ds = ds.select(range(100))\n",
    "\n",
    "    # convert to pandas dataframe\n",
    "    df_dict[model.split(\"_\")[-1]] = ds.to_pandas()\n",
    "    \n",
    "    # select relevant columns\n",
    "    df_dict[model.split(\"_\")[-1]] = df_dict[model.split(\"_\")[-1]][COLUMNS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen25-14b: total of 3180000 samples\n",
      "eval_label\n",
      "2              689689\n",
      "3              625786\n",
      "5              575531\n",
      "4              569618\n",
      "1              527827\n",
      "refusal        189663\n",
      "PARSE ERROR      1886\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parse the eval_text column\n",
    "\n",
    "def parse_eval_text(eval_text):\n",
    "\n",
    "    for char in eval_text:\n",
    "        for i in range(1, 6):\n",
    "            if f\"{i}\" in char:\n",
    "                return i\n",
    "            \n",
    "    if \"refusal\" in eval_text.lower():\n",
    "        return \"refusal\"\n",
    "    \n",
    "    else:\n",
    "        return \"PARSE ERROR\"\n",
    "\n",
    "\n",
    "for model in df_dict:\n",
    "        \n",
    "        df_dict[model]['eval_label'] = df_dict[model]['eval_text'].apply(parse_eval_text)\n",
    "\n",
    "        # count values\n",
    "        print(f'{model}: total of {len(df_dict[model])} samples')\n",
    "        print(df_dict[model]['eval_label'].value_counts())\n",
    "        print()\n",
    "\n",
    "        # flag sample of PARSE ERRORS\n",
    "        #if len(df_dict[model][df_dict[model]['eval_label'] == 'PARSE ERROR']) > 0:\n",
    "        #    print(\"#\" * 80)\n",
    "        #    print(model)\n",
    "\n",
    "            #for _, row in df_dict[model][df_dict[model]['eval_label'] == 'PARSE ERROR'].sample(3,random_state=42).iterrows():\n",
    "            #    print(row['eval_text'])\n",
    "            #    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: qwen25-14b\n",
      "Total number of rows: 3180000\n",
      "Missing values in response_text: 0\n",
      "Missing values in eval_text: 0\n",
      "PARSE ERROR in eval_label: 1886\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sanity_checks(df):\n",
    "\n",
    "    # print total number of rows\n",
    "    print(f\"Total number of rows: {len(df)}\")\n",
    "\n",
    "    # assert that there is an equal number of rows for each call_idx\n",
    "    assert df.call_idx.value_counts().nunique() == 1\n",
    "\n",
    "    # assert that there is an equal number of rows for each topic_id\n",
    "    assert df.topic_id.value_counts().nunique() == 1\n",
    "\n",
    "    # count missing values in response_text\n",
    "    print(f\"Missing values in response_text: {df.response_text.isnull().sum()}\")\n",
    "\n",
    "    # count missing values in eval_text\n",
    "    print(f\"Missing values in eval_text: {df.eval_text.isnull().sum()}\")\n",
    "\n",
    "    # count PARSE ERROR in eval_label\n",
    "    print(f\"PARSE ERROR in eval_label: {df[df.eval_label == 'PARSE ERROR'].shape[0]}\")\n",
    "\n",
    "for model in df_dict:\n",
    "    print(f\"Model: {model}\")\n",
    "    sanity_checks(df_dict[model])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved qwen25-14b.csv\n"
     ]
    }
   ],
   "source": [
    "# store as csv \n",
    "\n",
    "for model in df_dict:\n",
    "    df_dict[model].to_csv(f\"../data/model_responses/{model}.csv\", index=False)\n",
    "    print(f\"Saved {model}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
