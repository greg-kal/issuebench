{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: krippendorff in /opt/anaconda3/lib/python3.12/site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy<3,>=1.21 in /opt/anaconda3/lib/python3.12/site-packages (from krippendorff) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the krippendorff module if not already installed\n",
    "%pip install krippendorff\n",
    "\n",
    "import pandas as pd\n",
    "import krippendorff\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_categorical(df, column):\n",
    "    \"\"\"\n",
    "    Summarise a categorical column in a DataFrame.\n",
    "    \"\"\"\n",
    "    summary = pd.DataFrame({\n",
    "        'Count': df[column].value_counts(),\n",
    "        'Proportion': df[column].value_counts(normalize=True)\n",
    "        })\n",
    "    \n",
    "    summary[\"Proportion\"] = summary[\"Proportion\"].apply(lambda x: f\"{x:.2%}\")\n",
    "    display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/greg/Desktop/newIB/issuebench/1_dataset_construction/2_relevance_filtering\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 - clear no</th>\n",
       "      <td>939</td>\n",
       "      <td>93.90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 - clear yes</th>\n",
       "      <td>51</td>\n",
       "      <td>5.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borderline</th>\n",
       "      <td>9</td>\n",
       "      <td>0.90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1- clear yes</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Count Proportion\n",
       "final_label                    \n",
       "0 - clear no     939     93.90%\n",
       "1 - clear yes     51      5.10%\n",
       "borderline         9      0.90%\n",
       "1- clear yes       1      0.10%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the annotations\n",
    "print(os.getcwd())\n",
    "df = pd.read_csv(\"/Users/greg/Desktop/newIB/issuebench/\" \\\n",
    "\"final_labeled_GK_CH/final_GK_CH_annotations.csv\")\n",
    "\n",
    "# summarise the 'final_label' column\n",
    "summarise_categorical(df, \"final_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disagreement</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>986</td>\n",
       "      <td>98.60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>14</td>\n",
       "      <td>1.40%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Count Proportion\n",
       "disagreement                  \n",
       "False           986     98.60%\n",
       "True             14      1.40%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The following categories are not in the specified order: {'1- clear yes', nan}\n",
      "Krippendorff's alpha: 0.9036\n"
     ]
    }
   ],
   "source": [
    "def krippendorff_alpha(data, level_of_measurement='nominal', category_order=None):\n",
    "    \"\"\"Calculate Krippendorff's alpha for the given data.\"\"\"\n",
    "    # Create a pivot table with ratings as values\n",
    "    pivot_table = data[[\"annot1_label\", \"annot2_label\"]]\n",
    "    \n",
    "    # Convert string category names to numeric values\n",
    "    if category_order is not None:\n",
    "        # For ordinal data with specified order\n",
    "        # Check that all categories in the data are in the category_order\n",
    "        missing_categories = set(pivot_table.values.flatten()) - set(category_order)\n",
    "        if missing_categories:\n",
    "            print(f\"Warning: The following categories are not in the specified order: {missing_categories}\")\n",
    "\n",
    "        # Create a mapping from category to numeric value\n",
    "        category_map = {cat: i for i, cat in enumerate(category_order)}\n",
    "        \n",
    "        # Apply the mapping to convert categories to ordered numeric values\n",
    "        # Any values not in category_order will become NaN\n",
    "        pivot_table = pivot_table.apply(lambda x: x.map(category_map))\n",
    "    else:\n",
    "        # For nominal data without specified order\n",
    "        pivot_table = pivot_table.apply(lambda x: pd.factorize(x)[0])\n",
    "        # replace any -1 values with NaN\n",
    "        pivot_table = pivot_table.replace(-1, np.nan)\n",
    "\n",
    "    # Convert to a numpy array\n",
    "    ratings_array = pivot_table.to_numpy().T\n",
    "\n",
    "    # Calculate Krippendorff's alpha\n",
    "    alpha = krippendorff.alpha(reliability_data=ratings_array, level_of_measurement=level_of_measurement)\n",
    "    return alpha\n",
    "\n",
    "# summarise the 'disagreement' column, after filling NaN values with False\n",
    "df[\"disagreement\"] = df[\"disagreement\"].fillna(False)\n",
    "summarise_categorical(df, \"disagreement\")\n",
    "\n",
    "# Calculate Krippendorff's alpha for the 'annot1_label' and 'annot2_label' columns, using ordinal measurement\n",
    "alpha = krippendorff_alpha(df, level_of_measurement=\"ordinal\", category_order=[\"0 - clear no\", \"borderline\", \"1 - clear yes\"])\n",
    "print(f\"Krippendorff's alpha: {alpha:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annot1_label, annot1_notes, annot2_label, annot2_notes, disagreement, final_label\n",
    "df = pd.read_csv(\"/Users/greg/Desktop/newIB/issuebench/\" \\\n",
    "\"final_labeled_GK_CH/final_GK_CH_annotations.csv\")\n",
    "\n",
    "columns_to_remove = [\n",
    "    'annot1_label',\n",
    "    'annot1_notes',\n",
    "    'annot2_label',\n",
    "    'annot2_notes',\n",
    "    'disagreement',\n",
    "    'final_label'\n",
    "]\n",
    "\n",
    "df_pruned = df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "\n",
    "df_pruned.to_csv(\"/Users/greg/Desktop/newIB/issuebench/final_labeled_GK_CH/final_GK_CH_pruned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the prompt templates\n",
    "templates = pd.read_csv(\"./relevance_templates.csv\")\n",
    "\n",
    "def create_prompt(template, user_prompt):\n",
    "    \n",
    "    # remove linebreaks and tabs\n",
    "    user_prompt = user_prompt.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "\n",
    "    # collapse multiple spaces into one\n",
    "    user_prompt = \" \".join(user_prompt.split())\n",
    "\n",
    "    return template.format(user_prompt = user_prompt)\n",
    "\n",
    "df_dict = {}\n",
    "\n",
    "for i, row in templates.iterrows():\n",
    "    df_dict[row[\"id\"]] = df.copy()\n",
    "    df_dict[row[\"id\"]][\"eval_prompt\"] = df_dict[row[\"id\"]][\"user_prompt\"].apply(lambda x: create_prompt(row[\"prompt_template\"], x))\n",
    "\n",
    "# save the eval prompt dfs to csv files\n",
    "for i in df_dict:\n",
    "    df_dict[i].to_csv(\"./eval_prompts/relevance_210725_prompts_{}.csv\".format(i), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_clean_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/greg/Desktop/newFolderLLM/issuebench/1_dataset_construction/1_preprocessing/\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean/all_clean_dups.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_clean_df\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "all_clean_df = pd.read_csv(\"/Users/greg/Desktop/newFolderLLM/issuebench/1_dataset_construction/1_preprocessing/\" \\\n",
    "\"clean/all_clean_dups.csv\")\n",
    "print(all_clean_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/greg/Desktop/newFolderLLM/issuebench/1_dataset_construction/2_relevance_filtering\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply best prompt template (see notebook 2_) to all clean samples\n",
    "\n",
    "# all_clean_df = pd.read_csv(\"../data/clean/all_clean.csv\")\n",
    "all_clean_df = pd.read_csv(\"/Users/greg/Desktop/newFolderLLM/issuebench/1_dataset_construction/2_relevance_filtering/final_GK_CH_annotations.csv\")\n",
    "all_clean_df[\"eval_prompt\"] = all_clean_df[\"user_prompt\"].apply(lambda x: create_prompt(templates.iloc[4][\"prompt_template\"], x))\n",
    "all_clean_df.to_csv(\"../data/clean/all_clean_prompts.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
