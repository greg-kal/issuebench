{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: krippendorff in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.8.1)\n",
      "Requirement already satisfied: numpy<3,>=1.21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from krippendorff) (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the krippendorff module if not already installed\n",
    "%pip install krippendorff\n",
    "\n",
    "import pandas as pd\n",
    "import krippendorff\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_categorical(df, column):\n",
    "    \"\"\"\n",
    "    Summarise a categorical column in a DataFrame.\n",
    "    \"\"\"\n",
    "    summary = pd.DataFrame({\n",
    "        'Count': df[column].value_counts(),\n",
    "        'Proportion': df[column].value_counts(normalize=True)\n",
    "        })\n",
    "    \n",
    "    summary[\"Proportion\"] = summary[\"Proportion\"].apply(lambda x: f\"{x:.2%}\")\n",
    "    display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 - clear no</th>\n",
       "      <td>845</td>\n",
       "      <td>84.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borderline</th>\n",
       "      <td>80</td>\n",
       "      <td>8.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 - clear yes</th>\n",
       "      <td>75</td>\n",
       "      <td>7.50%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Count Proportion\n",
       "final_label                    \n",
       "0 - clear no     845     84.50%\n",
       "borderline        80      8.00%\n",
       "1 - clear yes     75      7.50%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the annotations\n",
    "df = pd.read_csv(\"./relevance_annotations.csv\")\n",
    "\n",
    "# summarise the 'final_label' column\n",
    "summarise_categorical(df, \"final_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/bh2hzf9x46j_xbc8kphs38dm0000gn/T/ipykernel_75071/2038977520.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"disagreement\"] = df[\"disagreement\"].fillna(False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disagreement</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>964</td>\n",
       "      <td>96.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>36</td>\n",
       "      <td>3.60%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Count Proportion\n",
       "disagreement                  \n",
       "False           964     96.40%\n",
       "True             36      3.60%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krippendorff's alpha: 0.9745\n"
     ]
    }
   ],
   "source": [
    "def krippendorff_alpha(data, level_of_measurement='nominal', category_order=None):\n",
    "    \"\"\"Calculate Krippendorff's alpha for the given data.\"\"\"\n",
    "    # Create a pivot table with ratings as values\n",
    "    pivot_table = data[[\"annot1_label\", \"annot2_label\"]]\n",
    "    \n",
    "    # Convert string category names to numeric values\n",
    "    if category_order is not None:\n",
    "        # For ordinal data with specified order\n",
    "        # Check that all categories in the data are in the category_order\n",
    "        missing_categories = set(pivot_table.values.flatten()) - set(category_order)\n",
    "        if missing_categories:\n",
    "            print(f\"Warning: The following categories are not in the specified order: {missing_categories}\")\n",
    "\n",
    "        # Create a mapping from category to numeric value\n",
    "        category_map = {cat: i for i, cat in enumerate(category_order)}\n",
    "        \n",
    "        # Apply the mapping to convert categories to ordered numeric values\n",
    "        # Any values not in category_order will become NaN\n",
    "        pivot_table = pivot_table.apply(lambda x: x.map(category_map))\n",
    "    else:\n",
    "        # For nominal data without specified order\n",
    "        pivot_table = pivot_table.apply(lambda x: pd.factorize(x)[0])\n",
    "        # replace any -1 values with NaN\n",
    "        pivot_table = pivot_table.replace(-1, np.nan)\n",
    "\n",
    "    # Convert to a numpy array\n",
    "    ratings_array = pivot_table.to_numpy().T\n",
    "\n",
    "    # Calculate Krippendorff's alpha\n",
    "    alpha = krippendorff.alpha(reliability_data=ratings_array, level_of_measurement=level_of_measurement)\n",
    "    return alpha\n",
    "\n",
    "# summarise the 'disagreement' column, after filling NaN values with False\n",
    "df[\"disagreement\"] = df[\"disagreement\"].fillna(False)\n",
    "summarise_categorical(df, \"disagreement\")\n",
    "\n",
    "# Calculate Krippendorff's alpha for the 'annot1_label' and 'annot2_label' columns, using ordinal measurement\n",
    "alpha = krippendorff_alpha(df, level_of_measurement=\"ordinal\", category_order=[\"0 - clear no\", \"borderline\", \"1 - clear yes\"])\n",
    "print(f\"Krippendorff's alpha: {alpha:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the prompt templates\n",
    "templates = pd.read_csv(\"./relevance_templates.csv\")\n",
    "\n",
    "def create_prompt(template, user_prompt):\n",
    "    \n",
    "    # remove linebreaks and tabs\n",
    "    user_prompt = user_prompt.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "\n",
    "    # collapse multiple spaces into one\n",
    "    user_prompt = \" \".join(user_prompt.split())\n",
    "\n",
    "    return template.format(user_prompt = user_prompt)\n",
    "\n",
    "df_dict = {}\n",
    "\n",
    "for i, row in templates.iterrows():\n",
    "    df_dict[row[\"id\"]] = df.copy()\n",
    "    df_dict[row[\"id\"]][\"eval_prompt\"] = df_dict[row[\"id\"]][\"user_prompt\"].apply(lambda x: create_prompt(row[\"prompt_template\"], x))\n",
    "\n",
    "# save the eval prompt dfs to csv files\n",
    "for i in df_dict:\n",
    "    df_dict[i].to_csv(\"./eval_prompts/relevance_160424_prompts_{}.csv\".format(i), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['eval_prompt', 'user_prompt'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "all_clean_df = pd.read_csv(\"../data/clean/all_clean.csv\")\n",
    "print(all_clean_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/greg/Desktop/newFolderLLM/issuebench/1_dataset_construction/2_relevance_filtering\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply best prompt template (see notebook 2_) to all clean samples\n",
    "\n",
    "# all_clean_df = pd.read_csv(\"../data/clean/all_clean.csv\")\n",
    "all_clean_df = pd.read_csv(\"/Users/greg/Desktop/newFolderLLM/issuebench/1_dataset_construction/2_relevance_filtering/relevance_annotations.csv\")\n",
    "all_clean_df[\"eval_prompt\"] = all_clean_df[\"user_prompt\"].apply(lambda x: create_prompt(templates.iloc[4][\"prompt_template\"], x))\n",
    "all_clean_df.to_csv(\"../data/clean/all_clean_prompts.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
