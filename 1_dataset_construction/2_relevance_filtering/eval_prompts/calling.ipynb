{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b896754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1092a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model, ollama API, input files\n",
    "model_name = \"phi4-reasoning:plus\" # model name here\n",
    "ollama_url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "input_files = [\n",
    "    \"relevance_210725_prompts_templ-1.csv\",\n",
    "    \"relevance_210725_prompts_templ-2.csv\",\n",
    "    \"relevance_210725_prompts_templ-3.csv\",\n",
    "    \"relevance_210725_prompts_templ-4.csv\",\n",
    "    \"relevance_210725_prompts_templ-5.csv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e81ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 10:29:26,207 - INFO - Starting optimized processing\n",
      "2025-07-24 10:29:26,208 - INFO - - Model: phi4-reasoning:plus\n",
      "2025-07-24 10:29:26,209 - INFO - - Ollama URL: http://localhost:11434/api/generate\n",
      "2025-07-24 10:29:26,210 - INFO - - Max workers: 12\n",
      "2025-07-24 10:29:26,211 - INFO - Processing relevance_210725_prompts_templ-1.csv -> relevance_210725_completions_phi4-reasoning-plus-templ-1.csv\n",
      "2025-07-24 10:29:26,225 - INFO - Starting processing of 1000 items with 12 workers\n",
      "2025-07-24 10:31:56,322 - INFO - Progress: 5/1000 (0.5%) | Avg: 30.0s | ETA: 497.8min\n",
      "2025-07-24 10:31:56,362 - INFO - Progress: 10/1000 (1.0%) | Avg: 15.0s | ETA: 247.7min\n"
     ]
    }
   ],
   "source": [
    "# after many-a trial, thisscript finally works\n",
    "# GK NOTE 23 JULY: Saw script run supervised for templ-1, now leaving to run templ 2-5\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import logging\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Configuration\n",
    "MAX_WORKERS = 12  # Increased workers for slow model\n",
    "TEST_SUBSET = None # None to process all rows\n",
    "REQUEST_TIMEOUT = 150# Longer timeout but with aggressive parallelization\n",
    "RETRY_ATTEMPTS = 1  # Reduced retries to fail fast\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class OllamaProcessor:\n",
    "    \"\"\"Optimized Ollama API processor with yes/no normalization.\"\"\"\n",
    "    \n",
    "    def __init__(self, url: str, model: str, max_workers: int = MAX_WORKERS):\n",
    "        self.url = url\n",
    "        self.model = model\n",
    "        self.max_workers = max_workers\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\"Content-Type\": \"application/json\"})\n",
    "        adapter = requests.adapters.HTTPAdapter(\n",
    "            pool_connections=max_workers,\n",
    "            pool_maxsize=max_workers * 2,\n",
    "            max_retries=0\n",
    "        )\n",
    "        self.session.mount(\"http://\", adapter)\n",
    "        self.session.mount(\"https://\", adapter)\n",
    "        \n",
    "    def create_payload(self, prompt: str) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"model\": self.model,\n",
    "            \"prompt\": prompt.strip(),\n",
    "            \"stream\": False,\n",
    "            \"options\": {\n",
    "                \"temperature\": 0.0,\n",
    "                \"top_p\": 0.1,\n",
    "                \"num_predict\": -1,\n",
    "                \"num_ctx\": 4096,\n",
    "                \"repeat_penalty\": 1.0\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def normalize_response(self, text: str) -> str:\n",
    "        \"\"\"Strip <think>â€¦</think>, then normalize to Yes/No if response ends with them.\"\"\"\n",
    "        if not text:\n",
    "            return \"Error: Empty response\"\n",
    "        text = text.strip()\n",
    "        # Remove any <think>...</think> block\n",
    "        m = re.search(r'<think>.*?</think>\\s*(.*)', text, re.IGNORECASE | re.DOTALL)\n",
    "        if m:\n",
    "            text = m.group(1).strip()\n",
    "\n",
    "        low = text.lower().rstrip('.!?')  # drop any trailing punctuation\n",
    "        if low.endswith(\"yes\"):\n",
    "            return \"Yes\"\n",
    "        if low.endswith(\"no\"):\n",
    "            return \"No\"\n",
    "        return text  # fallback to full text\n",
    "\n",
    "    \n",
    "    def extract_response_text(self, result: Any) -> str:\n",
    "        \"\"\"Extract text from various Ollama JSON shapes.\"\"\"\n",
    "        if isinstance(result, dict):\n",
    "            for key in (\"response\", \"output\", \"content\"):\n",
    "                if key in result and isinstance(result[key], str):\n",
    "                    return result[key].strip()\n",
    "            # Chat-style\n",
    "            if \"choices\" in result and isinstance(result[\"choices\"], list):\n",
    "                msg = result[\"choices\"][0].get(\"message\", {})\n",
    "                return msg.get(\"content\", \"\").strip()\n",
    "            if \"message\" in result and isinstance(result[\"message\"], dict):\n",
    "                return result[\"message\"].get(\"content\", \"\").strip()\n",
    "            return str(result)\n",
    "        if isinstance(result, list) and result:\n",
    "            return str(result[0])\n",
    "        return str(result)\n",
    "\n",
    "    def call_ollama_single(self, prompt: str) -> str:\n",
    "        if not prompt:\n",
    "            return \"Error: Empty prompt\"\n",
    "        payload = self.create_payload(prompt)\n",
    "        for attempt in range(RETRY_ATTEMPTS + 1):\n",
    "            try:\n",
    "                resp = self.session.post(self.url, json=payload, timeout=REQUEST_TIMEOUT)\n",
    "                if resp.status_code == 200:\n",
    "                    try:\n",
    "                        result = resp.json()\n",
    "                        text = self.extract_response_text(result)\n",
    "                        return self.normalize_response(text)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        return f\"JSONError: {e}\"\n",
    "                else:\n",
    "                    return f\"HTTPError: {resp.status_code}\"\n",
    "            except requests.exceptions.Timeout:\n",
    "                return \"TimeoutError: Request timed out\"\n",
    "            except requests.exceptions.ConnectionError as e:\n",
    "                return f\"ConnectionError: {e}\"\n",
    "            except Exception as e:\n",
    "                return f\"UnexpectedError: {e}\"\n",
    "        return \"Error: All retry attempts failed\"\n",
    "    \n",
    "    def process_all_parallel(self, data_items: List[tuple]) -> List[tuple]:\n",
    "        \"\"\"Process items in parallel and report accurate ETA.\"\"\"\n",
    "        total = len(data_items)\n",
    "        completed = 0\n",
    "        results: List[tuple] = []\n",
    "        start = time.perf_counter()\n",
    "        \n",
    "        logger.info(f\"Starting processing of {total} items with {self.max_workers} workers\")\n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            future_to_idx = {executor.submit(self.call_ollama_single, prompt): idx\n",
    "                             for idx, prompt in data_items}\n",
    "            \n",
    "            for future in as_completed(future_to_idx):\n",
    "                idx = future_to_idx[future]\n",
    "                try:\n",
    "                    res = future.result()\n",
    "                except Exception as e:\n",
    "                    res = f\"FutureError: {e}\"\n",
    "                    logger.error(f\"Error in future for row {idx}: {e}\")\n",
    "                results.append((idx, res))\n",
    "                completed += 1\n",
    "\n",
    "                if completed % 5 == 0 or completed == total:\n",
    "                    elapsed = time.perf_counter() - start\n",
    "                    avg = elapsed / completed\n",
    "                    remaining = total - completed\n",
    "                    eta_sec = remaining * avg\n",
    "                    eta_min = eta_sec / 60\n",
    "                    logger.info(\n",
    "                        f\"Progress: {completed}/{total} ({100*completed/total:.1f}%) | \"\n",
    "                        f\"Avg: {avg:.1f}s | ETA: {eta_min:.1f}min\"\n",
    "                    )\n",
    "\n",
    "        return results\n",
    "\n",
    "def process_file_optimized(input_path: str, processor: OllamaProcessor):\n",
    "    match = re.search(r\"templ-\\d+\", input_path)\n",
    "    if not match:\n",
    "        logger.warning(f\"Skipping {input_path}, no template tag found.\")\n",
    "        return\n",
    "    template_tag = match.group()\n",
    "    model_tag = processor.model.replace(\":\", \"-\")\n",
    "    output_path = f\"relevance_210725_completions_{model_tag}-{template_tag}.csv\"\n",
    "    \n",
    "    logger.info(f\"Processing {input_path} -> {output_path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(input_path, encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read {input_path}: {e}\")\n",
    "        return\n",
    "    if df.empty:\n",
    "        logger.error(f\"No data in {input_path}\")\n",
    "        return\n",
    "    \n",
    "    # Ensure eval_prompt column\n",
    "    if 'eval_prompt' not in df.columns:\n",
    "        df.rename(columns={df.columns[-1]: 'eval_prompt'}, inplace=True)\n",
    "    \n",
    "    # changed to None to run through templ-1 file\n",
    "    if TEST_SUBSET and len(df) > TEST_SUBSET:\n",
    "        df = df.head(TEST_SUBSET).copy()\n",
    "        logger.info(f\"TEST MODE: Processing first {len(df)} rows\")\n",
    "    \n",
    "    df['eval_completion'] = None\n",
    "    df['model'] = processor.model\n",
    "    \n",
    "    valid = df['eval_prompt'].notna() & (df['eval_prompt'] != \"\")\n",
    "    valid_indices = df[valid].index.tolist()\n",
    "    if not valid_indices:\n",
    "        logger.error(\"No valid prompts to process.\")\n",
    "        return\n",
    "    \n",
    "    # Parallel processing\n",
    "    data = [(idx, df.at[idx, 'eval_prompt']) for idx in valid_indices]\n",
    "    t0 = time.perf_counter()\n",
    "    results = processor.process_all_parallel(data)\n",
    "    total_time = time.perf_counter() - t0\n",
    "    \n",
    "    # Update DataFrame\n",
    "    for idx, completion in results:\n",
    "        df.at[idx, 'eval_completion'] = completion\n",
    "    \n",
    "    # Summary stats\n",
    "    successful = df['eval_completion'].notna().sum()\n",
    "    errors = df['eval_completion'].str.contains('Error:', na=False).sum()\n",
    "    timeouts = df['eval_completion'].str.contains('TimeoutError:', na=False).sum()\n",
    "    rate = 100 * (successful - errors) / len(df)\n",
    "    \n",
    "    logger.info(\"=\"*50)\n",
    "    logger.info(f\"Finished in {total_time/60:.2f} minutes\")\n",
    "    logger.info(f\"Rows processed: {len(df)} (Valid: {len(valid_indices)})\")\n",
    "    logger.info(f\"Successes: {successful - errors}, Errors: {errors} (Timeouts: {timeouts})\")\n",
    "    logger.info(f\"Success rate: {rate:.1f}%\")\n",
    "    logger.info(f\"Throughput: {len(valid_indices)/(total_time/60):.1f} req/min\")\n",
    "    logger.info(\"=\"*50)\n",
    "    \n",
    "    # Save\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "        logger.info(f\"Saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save {output_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    logger.info(\"Starting optimized processing\")\n",
    "    logger.info(f\"- Model: {model_name}\")\n",
    "    logger.info(f\"- Ollama URL: {ollama_url}\")\n",
    "    logger.info(f\"- Max workers: {MAX_WORKERS}\")\n",
    "    if TEST_SUBSET:\n",
    "        logger.info(f\"- TEST SUBSET: {TEST_SUBSET} rows\")\n",
    "    \n",
    "    processor = OllamaProcessor(ollama_url, model_name, MAX_WORKERS)\n",
    "    \n",
    "    for input_path in input_files:\n",
    "        if not Path(input_path).exists():\n",
    "            logger.error(f\"File not found: {input_path}\")\n",
    "            continue\n",
    "        process_file_optimized(input_path, processor)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "# one file took 184 minutes, only 4.6% timeout error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1867ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original, took to long\n",
    "\n",
    "for input_path in input_files:\n",
    "    # Determine output file name based on template number and model\n",
    "    template_match = re.search(r\"templ-\\d+\", input_path)\n",
    "    if not template_match:\n",
    "        continue\n",
    "    template_tag = template_match.group() \n",
    "    # replace colon with hyphen in models\n",
    "    model_tag = model_name.replace(\":\", \"-\")\n",
    "    output_path = f\"relevance_210725_completions_{model_tag}-{template_tag}.csv\"\n",
    "    \n",
    "    with open(input_path, newline='', encoding='utf-8') as infile, \\\n",
    "         open(output_path, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "        \n",
    "        # Read the header and append new column names\n",
    "        header = next(reader)\n",
    "        new_header = header + [\"eval_completion\", \"model\"]\n",
    "        writer.writerow(new_header)\n",
    "        \n",
    "        # Iterate over each row in the input CSV\n",
    "        for row in reader:\n",
    "            if not row:  # skip empty lines if any\n",
    "                continue\n",
    "            prompt = row[-1]  # eval_prompt is the last col\n",
    "            \n",
    "            # Prepare the JSON payload for Ollama API\n",
    "            payload = {\n",
    "                \"model\": model_name,\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False  # get a single JSON response instead of stream\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.post(ollama_url, headers={\"Content-Type\": \"application/json\"},\n",
    "                                         data=json.dumps(payload))\n",
    "            except Exception as e:\n",
    "                # If there's a connection error or similar, you might want to handle it\n",
    "                print(f\"Error calling Ollama API for prompt: {prompt[:30]}... \\n{e}\")\n",
    "                continue\n",
    "            \n",
    "            eval_completion = \"\"\n",
    "            if response.status_code == 200:\n",
    "                # Parse JSON response from Ollama\n",
    "                try:\n",
    "                    result = response.json()\n",
    "                except ValueError:\n",
    "                    # If response is not a valid JSON (unexpected), use raw text\n",
    "                    result_text = response.text.strip()\n",
    "                    # Determine yes/no from text\n",
    "                    if result_text.lower().startswith(\"yes\"):\n",
    "                        eval_completion = \"Yes\"\n",
    "                    elif result_text.lower().startswith(\"no\"):\n",
    "                        eval_completion = \"No\"\n",
    "                    else:\n",
    "                        eval_completion = result_text  # fallback to whatever it is\n",
    "                else:\n",
    "                    # Ollama's response JSON might have the output text in a field.\n",
    "                    # We attempt common possible keys.\n",
    "                    if \"response\" in result:\n",
    "                        result_text = result[\"response\"]\n",
    "                    elif \"output\" in result:\n",
    "                        result_text = result[\"output\"]\n",
    "                    elif \"content\" in result:\n",
    "                        # If using chat-style response, it might be nested:\n",
    "                        # e.g., {\"model\": ..., \"choices\": [{\"message\": {\"role\": \"assistant\", \"content\": \"Yes\"}}], ...}\n",
    "                        result_text = result.get(\"content\", \"\") or result.get(\"message\", {}).get(\"content\", \"\")\n",
    "                    else:\n",
    "                        # If none of the known keys, use the full JSON string as fallback\n",
    "                        result_text = str(result)\n",
    "                    result_text = str(result_text).strip()\n",
    "                    # Normalize to \"Yes\" or \"No\"\n",
    "                    if result_text.lower().startswith(\"yes\"):\n",
    "                        eval_completion = \"Yes\"\n",
    "                    elif result_text.lower().startswith(\"no\"):\n",
    "                        eval_completion = \"No\"\n",
    "                    else:\n",
    "                        eval_completion = result_text\n",
    "            else:\n",
    "                # If the API call failed (non-200 status), record the status or an error\n",
    "                eval_completion = f\"Error: HTTP {response.status_code}\"\n",
    "            \n",
    "            # Append the new columns to the row\n",
    "            row_with_output = row + [eval_completion, model_name]\n",
    "            writer.writerow(row_with_output)\n",
    "\n",
    "    print(f\"Completed {input_path} -> {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
