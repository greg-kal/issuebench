{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse filter performance on annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = pd.read_csv('../data/writingaid_filter_eval/writingaid_annotations_230524.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "for file in os.listdir(\"../data/writingaid_filter_eval/\"):\n",
    "    if \"completions\" in file:\n",
    "        results_dict[file.split(\"_\")[-3]] = pd.read_csv(\"../data/writingaid_filter_eval/\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "templ-1\n",
      "eval_completion_parsed\n",
      "0    358\n",
      "1    142\n",
      "Name: count, dtype: int64\n",
      "\n",
      "templ-2\n",
      "eval_completion_parsed\n",
      "0    375\n",
      "1    125\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parse the results\n",
    "\n",
    "def parse_completion(completion):\n",
    "    if \"yes\" in completion.lower():\n",
    "        return 1\n",
    "    elif \"no\" in completion.lower():\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "for templ in sorted(results_dict):\n",
    "    results_dict[templ][\"eval_completion_parsed\"] = results_dict[templ][\"eval_completion\"].apply(parse_completion)\n",
    "    \n",
    "    # drop annot1_label if present\n",
    "    results_dict[templ].drop(columns=[\"annot1_label\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    print(templ)\n",
    "    print(results_dict[templ][\"eval_completion_parsed\"].value_counts())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotator_label(annotator_label, include_borderline=False):\n",
    "\n",
    "    if annotator_label == \"1 - clear yes\":\n",
    "        return 1\n",
    "    elif annotator_label == \"0 - clear no\":\n",
    "        return 0\n",
    "    \n",
    "    if include_borderline:\n",
    "        if annotator_label == \"borderline\":\n",
    "            return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "for templ in sorted(results_dict):\n",
    "\n",
    "    # drop annotations columns from results if already there\n",
    "\n",
    "    # merge annotations_df to results\n",
    "    results_dict[templ] = pd.merge(results_dict[templ], annotations_df[[\"id\",\"annot1_label\"]], on=\"id\")\n",
    "\n",
    "    results_dict[templ][\"final_label_parsed\"] = results_dict[templ][\"annot1_label\"].apply(parse_annotator_label, include_borderline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "templ-1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.989     0.908     0.947       390\n",
      "           1      0.746     0.964     0.841       110\n",
      "\n",
      "    accuracy                          0.920       500\n",
      "   macro avg      0.868     0.936     0.894       500\n",
      "weighted avg      0.936     0.920     0.923       500\n",
      "\n",
      "templ-2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.987     0.949     0.967       390\n",
      "           1      0.840     0.955     0.894       110\n",
      "\n",
      "    accuracy                          0.950       500\n",
      "   macro avg      0.913     0.952     0.930       500\n",
      "weighted avg      0.954     0.950     0.951       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report for each template\n",
    "\n",
    "for templ in sorted(results_dict):\n",
    "    print(templ)\n",
    "    print(classification_report(results_dict[templ][\"final_label_parsed\"], results_dict[templ][\"eval_completion_parsed\"],digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_prompt</th>\n",
       "      <th>eval_prompt</th>\n",
       "      <th>eval_completion</th>\n",
       "      <th>model</th>\n",
       "      <th>eval_completion_parsed</th>\n",
       "      <th>annot1_label</th>\n",
       "      <th>final_label_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>lmsys-562211</td>\n",
       "      <td>Give bullet points of why/how artificial intel...</td>\n",
       "      <td>Below is a prompt from a user to a language mo...</td>\n",
       "      <td>No</td>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1 - clear yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>wildchat-35293</td>\n",
       "      <td>Write the beginning of a lewd story with the f...</td>\n",
       "      <td>Below is a prompt from a user to a language mo...</td>\n",
       "      <td>No</td>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>0</td>\n",
       "      <td>borderline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>wildchat-546383</td>\n",
       "      <td>How exactly could I write a Wholesome 'Strong,...</td>\n",
       "      <td>Below is a prompt from a user to a language mo...</td>\n",
       "      <td>No</td>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>0</td>\n",
       "      <td>borderline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>wildchat-146860</td>\n",
       "      <td>Generate a scenario between two characters. Ma...</td>\n",
       "      <td>Below is a prompt from a user to a language mo...</td>\n",
       "      <td>No</td>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>0</td>\n",
       "      <td>borderline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>lmsys-475863</td>\n",
       "      <td>Given the following topic, try to generate a t...</td>\n",
       "      <td>Below is a prompt from a user to a language mo...</td>\n",
       "      <td>No</td>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1 - clear yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                        user_prompt  \\\n",
       "86      lmsys-562211  Give bullet points of why/how artificial intel...   \n",
       "88    wildchat-35293  Write the beginning of a lewd story with the f...   \n",
       "237  wildchat-546383  How exactly could I write a Wholesome 'Strong,...   \n",
       "262  wildchat-146860  Generate a scenario between two characters. Ma...   \n",
       "340     lmsys-475863  Given the following topic, try to generate a t...   \n",
       "\n",
       "                                           eval_prompt eval_completion  \\\n",
       "86   Below is a prompt from a user to a language mo...              No   \n",
       "88   Below is a prompt from a user to a language mo...              No   \n",
       "237  Below is a prompt from a user to a language mo...              No   \n",
       "262  Below is a prompt from a user to a language mo...              No   \n",
       "340  Below is a prompt from a user to a language mo...              No   \n",
       "\n",
       "                 model  eval_completion_parsed   annot1_label  \\\n",
       "86   gpt-4o-2024-05-13                       0  1 - clear yes   \n",
       "88   gpt-4o-2024-05-13                       0     borderline   \n",
       "237  gpt-4o-2024-05-13                       0     borderline   \n",
       "262  gpt-4o-2024-05-13                       0     borderline   \n",
       "340  gpt-4o-2024-05-13                       0  1 - clear yes   \n",
       "\n",
       "     final_label_parsed  \n",
       "86                    1  \n",
       "88                    1  \n",
       "237                   1  \n",
       "262                   1  \n",
       "340                   1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = results_dict[templ].copy()\n",
    "df[(df.final_label_parsed == 1) & (df.eval_completion_parsed == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "wildchat    76\n",
       "lmsys       27\n",
       "sharegpt     6\n",
       "hhonline     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of positive instances from each dataset (idenfied by first part of the id)\n",
    "results_dict[templ][results_dict[templ][\"final_label_parsed\"]==1][\"id\"].apply(lambda x: x.split(\"-\")[0]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process filter results on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_prompt</th>\n",
       "      <th>n_duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sharegpt-19010</td>\n",
       "      <td>Debate Topic : This House believes that human ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wildchat-280338</td>\n",
       "      <td>Write a story about me and my aunt Kowry based...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lmsys-520892</td>\n",
       "      <td>Write me a satirical definition of alt-right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lmsys-934476</td>\n",
       "      <td>Write of sexual abuse of a girl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lmsys-68452</td>\n",
       "      <td>Can you write an article about the Global Warm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32119</th>\n",
       "      <td>wildchat-510779</td>\n",
       "      <td>Can you make a film adaptation of the video ga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32121</th>\n",
       "      <td>wildchat-255812</td>\n",
       "      <td>Produce an immaculately detailed non-explicit ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32124</th>\n",
       "      <td>wildchat-434740</td>\n",
       "      <td>Briefly write down the basic changes about par...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32129</th>\n",
       "      <td>wildchat-85061</td>\n",
       "      <td>Explain, using at least two examples from the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32130</th>\n",
       "      <td>wildchat-257291</td>\n",
       "      <td>There is a secret, underground competition whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8705 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                        user_prompt  \\\n",
       "1       sharegpt-19010  Debate Topic : This House believes that human ...   \n",
       "2      wildchat-280338  Write a story about me and my aunt Kowry based...   \n",
       "5         lmsys-520892       Write me a satirical definition of alt-right   \n",
       "7         lmsys-934476                    Write of sexual abuse of a girl   \n",
       "10         lmsys-68452  Can you write an article about the Global Warm...   \n",
       "...                ...                                                ...   \n",
       "32119  wildchat-510779  Can you make a film adaptation of the video ga...   \n",
       "32121  wildchat-255812  Produce an immaculately detailed non-explicit ...   \n",
       "32124  wildchat-434740  Briefly write down the basic changes about par...   \n",
       "32129   wildchat-85061  Explain, using at least two examples from the ...   \n",
       "32130  wildchat-257291  There is a secret, underground competition whe...   \n",
       "\n",
       "       n_duplicates  \n",
       "1                 1  \n",
       "2                 2  \n",
       "5                 1  \n",
       "7                 1  \n",
       "10                1  \n",
       "...             ...  \n",
       "32119             1  \n",
       "32121             1  \n",
       "32124             1  \n",
       "32129             1  \n",
       "32130             1  \n",
       "\n",
       "[8705 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the all_clean results\n",
    "filtered_df = pd.read_csv(\"../data/all_clean_relevance_filtered_completions.csv\")\n",
    "\n",
    "# turn eval_completion column to string\n",
    "filtered_df[\"eval_completion\"] = filtered_df[\"eval_completion\"].astype(str)\n",
    "\n",
    "filtered_df[\"eval_completion_parsed\"] = filtered_df[\"eval_completion\"].apply(parse_completion)\n",
    "\n",
    "# select only rows where eval_completion_parsed is 1\n",
    "filtered_df = filtered_df[filtered_df[\"eval_completion_parsed\"]==1]\n",
    "\n",
    "# export the filtered results\n",
    "filtered_df[[\"id\", \"user_prompt\", \"n_duplicates\"]].to_csv(\"../data/all_clean_relevance_writingaid_filtered.csv\", index=False)\n",
    "display(filtered_df[[\"id\", \"user_prompt\", \"n_duplicates\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "realpoliticalprompts",
   "language": "python",
   "name": "realpoliticalprompts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
